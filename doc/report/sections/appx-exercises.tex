% !TEX root = ../main.tex

% Exercises section

\section{Exercises}


\begin{exercise}[Adapted from \cite{Kingman:1978}] \label{ex:n_symmetric}
	Let $X = (X_n)_{n=1}^{\infty}$ be an exchangeable sequence of random variables taking values in a measurable space $(\calX, \calF)$ with common expectation. A random variable $Y = g(X)$ is said to be $n$-\textit{symmetric} if it is bounded and invariant under permutations of its first $n$ components, that is, if
	\begin{equation} \label{eq:n_symmetric}
		g(X_1, X_2, ...) = g(X_{\pi(1)}, ..., X_{\pi(n)}, X_{n+1}, ...)
	\end{equation}
	for every permutation $\pi$ of $\bbN_n$. Define $\calF_n$ to be the smallest $\sigma$-algebra with respect to which all $n$-symmetric random variables are measurable. Let $f$ be an integrable numerical $\calF$-measurable function, that is, $\bbE |f(X_n)| < \infty$ for all $n$. Prove that $\frac{1}{n} \sum_{j=1}^n f(X_j)$ is a version of $\bbE[ f(X_1) \, | \, \calF_n ]$ for every $n$.
\end{exercise}

\textbf{Solution \ref{ex:n_symmetric}. \hspace{0.05cm}} Fix $n \in \bbN$. Because the components of $X$ have common expectation, clearly $\bbE[f(X_1)] = \bbE[f(X_j)]$ for every $1 \leq j \leq n$ and, moreover, $\bbE[ f(X_1) g(X) ] = \bbE[ f(X_j) g(X) ]$ for every $g \in \calF_n$. Thus,
\begin{equation*}
	\bbE \left[ \frac{1}{n} \sum_{j=1}^n f(X_j) g(X) \right] = \frac{1}{n} \sum_{j=1}^n \bbE[ f(X_j) g(X) ] = \frac{1}{n} \sum_{j=1}^n \bbE[ f(X_1) g(X) ] = \bbE[ f(X_1) g(X) ],
\end{equation*}
and so $\frac{1}{n} \sum_{j=1}^n f(X_j)$ satisfies the projection property. Furthermore, it is clearly $n$-symmetric as a function of $X$, and hence is in $\calF_n$, which completes the proof. \\
\qed

\vskip 0.25cm

Observe also that $\calF_{n+1} \subset \calF_n$: if a function is $n+1$-symmetric it is also $n$-symmetric. A reverse-martingale argument \cite[see Theorem B.124 (LÃ©vy's theorem: part II) in][p.~650]{Schervish:1995} can be used to show that
\begin{equation} \label{eq:LLN_exch}
	\lim_{n \to \infty} \frac{1}{n} \sum_{j=1}^n f(X_j) = \bbE[ f(X_1) \, | \, \calF_{\infty}] \quad \mathrm{a.s.}, 
\end{equation}
where
\begin{equation*}
	\calF_{\infty} = \bigcap_{n=1}^{\infty} \calF_n.
\end{equation*}
Equation (\ref{eq:LLN_exch}) is a version of the Strong Law of Large Numbers for exchangeable sequences.

\vskip 0.75cm


\begin{exercise} \label{ex:GP_NF_local_exchangeable}
	Let $f(x) = (2/\pi) x$ and $X = (X_t)_{t \in \bbR} \sim \GP (0, \kappa)$ be a noise-free Gaussian process in $\bbR$, which we furthermore endow with the metric  $d(t, t') = |t-t'|$. Then $X$ is $f$-locally exchangeable. \\
	
	Hint: observe that $\kappa(t, t) = 1$.	For a finite subset $T \subset \bbR$, define $Y_T \equdist \calN ( 0, \tilde{K} )$, where $\tilde{K}$ is a matrix equal to $K(T, T)$ but with the diagonal elements divided by half.
\end{exercise}


\textbf{Solution \ref{ex:GP_NF_local_exchangeable}. \hspace{0.05cm}} Let $T \subset \bbR$ be a finite subset of size $n$ of the covariate space. We know that $X_T \equdist \calN (0, K)$, where $K = K(T,T)$. Furthermore, the diagonal of $K$ consists of 1's: $\kappa(t, t) = 1$ (see Equation (\ref{eq:sq_exp_cov}) with $\ell = 1$). Define $\tilde{K}$ to be a matrix equal to $K$ but with its diagonal elements divided by half:
\begin{equation*}
	\tilde{K}_{ij} = \begin{cases}
					  	\frac{1}{2}, & i=j, \\
					  	\kappa(t_i, t_j) & i \neq j.
					  \end{cases}
\end{equation*}
Now let $Y_T \equdist \calN(0, \tilde{K})$ and observe that $\bbP [ X_T \, | \, \sigma Y_T ] \equdist \calN \left( Y_T, \frac{1}{2} I_n \right)$. In other words, $X_T$ are conditionally independent given $Y_T$ because the latter captures the dependence structure in the sample. The argument that follows from here is identical to that of Proposition \ref{prop:GP_local_exchangeability}:
\begin{align*}
	d_{\mathrm{TV}} \left( \calN \left( Y_t, \frac{1}{2} \right) , \calN \left( Y_{t'}, \frac{1}{2} \right) \right) &= \Phi \left( |Y_t - Y_{t'} | \right) - \Phi \left( -|Y_t - Y_{t'} | \right) \\
		&\leq \sqrt{\frac{2}{\pi}} |Y_t - Y_{t'}|. && \text{(by Lemma \ref{lemma:lipschitz})}
\end{align*}
Now by Lemma \ref{lemma:halfnormal}
\begin{equation*}
	\bbE | Y_t - Y_{t'} | = \sqrt{\frac{4}{\pi}(1 - \kappa(t, t'))}
\end{equation*}
and so
\begin{equation*}
	\bbE \left[ d_{\mathrm{TV}} \left( \calN \left( Y_t, \frac{1}{2} \right) , \calN \left( Y_{t'}, \frac{1}{2} \right) \right) \right] \leq \sqrt{\frac{8}{\pi^2}(1 - \kappa(t, t'))} \leq \frac{2}{\pi} d(t, t'),
\end{equation*}
from where the result follows by Proposition \ref{prop:sufficient_local_exchangeability}.

\qed 

